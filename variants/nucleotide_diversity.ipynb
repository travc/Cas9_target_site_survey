{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T22:30:59.813409Z",
     "start_time": "2019-07-11T22:30:58.673228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.7 | packaged by conda-forge | (default, Feb 28 2019, 09:07:38) \n",
      "[GCC 7.3.0]\n",
      "numpy 1.16.2\n",
      "pandas 0.24.1\n",
      "scikit-allel 1.2.0\n",
      "zarr 2.2.0\n",
      "statsmodels 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import sys; print(sys.version)\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "import io\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "\n",
    "import numpy as np; print('numpy', np.__version__)\n",
    "import pandas as pd; print('pandas',pd.__version__)\n",
    "import allel; print('scikit-allel', allel.__version__)\n",
    "import zarr; print('zarr', zarr.__version__)\n",
    "import scipy.stats\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import statsmodels; print('statsmodels', statsmodels.__version__)\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T22:30:59.819645Z",
     "start_time": "2019-07-11T22:30:59.814874Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "mpl.rcParams['figure.facecolor'] = '#BBBBBB'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T22:30:59.828692Z",
     "start_time": "2019-07-11T22:30:59.821947Z"
    }
   },
   "outputs": [],
   "source": [
    "## Uncommnet blocks for each different set of samples\n",
    "\n",
    "# SETNAME = 'VGL-gam'\n",
    "# GENOME = 'AgamP4.11'\n",
    "# ZVCF = 'vcfs/YL-Agam-GF2_pflit.vcf.gz.zarr'\n",
    "# SAMPLE_LIST_FN = 'vcfs/hanno_Agam_sample_list.txt'\n",
    "\n",
    "# SETNAME = 'Ag1000g-gam'\n",
    "# GENOME = \"AgamP4.11\"\n",
    "# ZVCF = '/data/ag1000g_p2_ar1/ngs.sanger.ac.uk/production/ag1000g/phase2/AR1/variation/main/vcf/all/ag1000g.phase2.ar1.zarr'\n",
    "# SAMPLE_LIST_FN = ['S', '/data/ag1000g_p2_ar1/samples/samples.meta.txt'] # list implies ag1000g to be filtered on m_s\n",
    "\n",
    "# SETNAME = 'VGL-col'\n",
    "# GENOME = \"AgamP4.11\"\n",
    "# ZVCF = \"vcfs/100Acol_pflit.vcf.gz.zarr\"\n",
    "# SAMPLE_LIST_FN = None # use all samples in ZVCF\n",
    "\n",
    "# SETNAME = 'Ag1000g-col'\n",
    "# GENOME = \"AgamP4.11\"\n",
    "# ZVCF = '/data/ag1000g_p2_ar1/ngs.sanger.ac.uk/production/ag1000g/phase2/AR1/variation/main/vcf/all/ag1000g.phase2.ar1.zarr'\n",
    "# SAMPLE_LIST_FN = ['M', '/data/ag1000g_p2_ar1/samples/samples.meta.txt'] # list implies ag1000g to be filtered on m_s\n",
    "\n",
    "SETNAME = 'VGL-Aaeg'\n",
    "GENOME = \"Aaegypti_L5.1\"\n",
    "ZVCF = \"vcfs/YL-Aaeg-03_pflit.vcf.gz.zarr\"\n",
    "SAMPLE_LIST_FN = None # use all samples in ZVCF\n",
    "\n",
    "## automatically set based on GENOME\n",
    "if GENOME == 'AgamP4.11':\n",
    "    GENE_PREFIX = \"AGAP\"\n",
    "    CHROMS = ['2R','2L','3R','3L','X']\n",
    "    REF_FAI_FN = '/data/reference/Anopheles-gambiae-PEST_CHROMOSOMES_AgamP4.fa.fai'\n",
    "    GTFFN = '../datafiles/Anopheles-gambiae-PEST_BASEFEATURES_AgamP4.11.gtf'\n",
    "elif GENOME == 'Aaegypti_L5.1':\n",
    "    GENE_PREFIX = \"AAEL\"\n",
    "    CHROMS = ['1','2','3']\n",
    "    REF_FAI_FN = '/data/reference/AaegL5.fa.fai'\n",
    "    GTFFN = \"../datafiles/Aedes-aegypti-LVP_AGWG_BASEFEATURES_AaegL5.1.gtf\"\n",
    "else:\n",
    "    assert False, \"unknown GENOME '\"+GENOME+\"'\"\n",
    "\n",
    "# misc/testing\n",
    "SUBSAMPLE_N = None\n",
    "IGNORE_ONE_CALL_VARIANTS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get chrom sizes and CDS info\n",
    "`ref_fai` and `cdslist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T22:31:00.065323Z",
     "start_time": "2019-07-11T22:30:59.830421Z"
    }
   },
   "outputs": [],
   "source": [
    "ref_fai = pd.read_csv(REF_FAI_FN, delimiter='\\t', header=None, index_col=0,\n",
    "                      names=['len','offset','line_bases', 'line_width'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T22:31:01.877615Z",
     "start_time": "2019-07-11T22:31:00.067234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of genes in gtf: 19712\n",
      "Total coding size (sum of CDS lens) 59121227\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv(GTFFN, sep='\\t', comment='#', header=None,\n",
    "            names=['seqid',\n",
    "                   'source',\n",
    "                   'type',\n",
    "                   'start',\n",
    "                   'end',\n",
    "                   'score',\n",
    "                   'strand',\n",
    "                   'phase',\n",
    "                   'attributes'],\n",
    "                dtype={'seqid':str})\n",
    "\n",
    "# total number of genes\n",
    "t = d.loc[d['type']=='gene' ,:].copy(deep=True)\n",
    "t['gene_id'] = t['attributes'].apply(\n",
    "                    lambda x: dict([_.strip().split() for _ in\n",
    "                    x.split(';') if _])['gene_id'].strip('\"'))\n",
    "print(\"total number of genes in gtf:\", t['gene_id'].unique().shape[0])\n",
    "\n",
    "# list of CDS\n",
    "d = d.loc[d['type']=='CDS' ,:]\n",
    "d['gene_id'] = d['attributes'].apply(\n",
    "                    lambda x: dict([_.strip().split() for _ in\n",
    "                    x.split(';') if _])['gene_id'].strip('\"'))\n",
    "d['transcript_id'] = d['attributes'].apply(\n",
    "                    lambda x: dict([_.strip().split() for _ in\n",
    "                    x.split(';') if _])['transcript_id'].strip('\"'))\n",
    "# filter to only CRHOMS\n",
    "d = d.loc[d['seqid'].isin(CHROMS) ,:]\n",
    "cdslist = d\n",
    "\n",
    "print('Total coding size (sum of CDS lens)',(d['end']-d['start']+1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load callset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T22:31:02.170375Z",
     "start_time": "2019-07-11T22:31:01.878956Z"
    }
   },
   "outputs": [],
   "source": [
    "callset = zarr.open_group(ZVCF, mode='r')\n",
    "if CHROMS is None: # use all chroms?\n",
    "    CHROMS = list(callset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T22:31:36.418232Z",
     "start_time": "2019-07-11T22:31:02.172438Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples 132\n"
     ]
    }
   ],
   "source": [
    "if SAMPLE_LIST_FN is None: # use all samples\n",
    "    meta = pd.DataFrame(list(callset.values())[0]['samples'][:])\n",
    "    meta['callset_idx'] = range(meta.shape[0])\n",
    "else:\n",
    "    # load the sample list and make meta dataframe\n",
    "    if isinstance(SAMPLE_LIST_FN, str): # assume a simple list file\n",
    "        meta = pd.read_csv(SAMPLE_LIST_FN, comment='#', header=None, index_col=0)\n",
    "    else: # parse ag1000g samples.meta.txt with SAMPLE_LIST_FN really being [M|S,filename]\n",
    "        meta = pd.read_csv(SAMPLE_LIST_FN[1], delimiter='\\t', comment='#', index_col=0)\n",
    "        meta = meta[meta['m_s']==SAMPLE_LIST_FN[0]]\n",
    "    all_callset_samples = list(list(callset.values())[0]['samples'])\n",
    "    meta['callset_idx'] = [all_callset_samples.index(x) for x in meta.index]\n",
    "meta.index.name = 'sample'\n",
    "\n",
    "# Optionally subsample to check sample size effects\n",
    "if SUBSAMPLE_N:\n",
    "    meta = meta.sample(n=SUBSAMPLE_N)\n",
    "\n",
    "# ensure it is sorted by callset_idx (otherwise makes later steps terribly inefficient)\n",
    "meta = meta.sort_values('callset_idx')\n",
    "\n",
    "print(\"number of samples\",meta.shape[0])\n",
    "# meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute nucleotide diversity and depth of coverage\n",
    "over coding transcript loci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T22:34:35.094517Z",
     "start_time": "2019-07-11T22:31:36.420885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "coding transcript filter passes: 306081 of 19363735 = 1.581%\n",
      "variant filter passes: 19363735\n",
      "variants : 306081 of 19363735 = 1.581%\n",
      "2\n",
      "coding transcript filter passes: 452676 of 33785440 = 1.340%\n",
      "variant filter passes: 33785440\n",
      "variants : 452676 of 33785440 = 1.340%\n",
      "3\n",
      "coding transcript filter passes: 390104 of 27317076 = 1.428%\n",
      "variant filter passes: 27317076\n",
      "variants : 390104 of 27317076 = 1.428%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('1', 0.010523741627811483),\n",
       "             ('2', 0.009221635796237162),\n",
       "             ('3', 0.008789529658812079)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqdiv = OrderedDict()\n",
    "numloci = OrderedDict()\n",
    "dpmedian = OrderedDict()\n",
    "dpmean = OrderedDict()\n",
    "dpstd = OrderedDict()\n",
    "dpall = np.array([])\n",
    "\n",
    "for chrom in CHROMS:\n",
    "    print(chrom)\n",
    "\n",
    "    #### build mask of CDS positions for chrom\n",
    "    # (used as accessibility mask for calculatons)\n",
    "    chrom_len = ref_fai.loc[chrom,'len']\n",
    "    t = cdslist[cdslist['seqid']==chrom]\n",
    "    acc_mask = np.full((chrom_len), False, dtype=bool)\n",
    "    def _set_acc_mask(start, end):\n",
    "        acc_mask[start-1:end] = True # note mask is 0-baesd half open positions\n",
    "    _ = t.loc[:,['start','end']].apply(lambda x: _set_acc_mask(x['start'],x['end']), axis=1)\n",
    "\n",
    "    numloci[chrom] = acc_mask.sum()\n",
    "    \n",
    "    # display(acc_mask[157497:]) # AgamP4.11 2L should have False,True,True,...\n",
    "    # display(acc_mask[209814:]) # AgamP4.11 2L should have True,True,False,...\n",
    "\n",
    "    #### Load and filter the callset data for this chrom\n",
    "    ## Get the positions of variants on this chrom (possible subsetting samples)\n",
    "    pos = allel.SortedIndex(callset[chrom]['variants/POS'])\n",
    "    g = allel.GenotypeDaskArray(callset[chrom]['calldata/GT']).subset(None, meta['callset_idx'].values)\n",
    "    n_variants_in = g.shape[0]\n",
    "    \n",
    "    # ensure number of samples is same\n",
    "    assert meta.shape[0] == g.shape[1]\n",
    "    \n",
    "    # accessibility filter\n",
    "    flt = pos.locate_ranges(t['start'], t['end'], strict=False)\n",
    "    print(\"coding transcript filter passes: {} of {} = {:.3f}%\".format(\n",
    "        flt.sum(), flt.shape[0], 100*flt.sum()/flt.shape[0]))\n",
    "\n",
    "    # @TCC TEMP/DEBUG minimal code to disable acc_mask\n",
    "#     acc_mask = np.full((chrom_len), True, dtype=bool)\n",
    "#     flt = np.full((pos.shape[0]), True, dtype=bool)\n",
    "    \n",
    "    # depth of coverage over flt (coding transcripts) loci\n",
    "    d = callset[chrom]['calldata/DP']\n",
    "    d = d.get_orthogonal_selection((np.flatnonzero(flt), meta['callset_idx'].values))\n",
    "    d = d.clip(min=0) # replace all negative values with 0\n",
    "    dpmedian[chrom] = np.median(d)\n",
    "    dpmean[chrom] = d.flatten().mean()\n",
    "    dpstd[chrom] = d.flatten().std()\n",
    "    # @TCC TODO less memory apporach for median calcs histogram and adds them for each new chrom\n",
    "    dpall = np.concatenate((dpall, d.flatten())) # this makes a huge list (samples*all_loci)\n",
    "    del d\n",
    "    \n",
    "    # @TCC TODO should be able to speedup by applying filter to g here\n",
    "    \n",
    "    # get major allele frequencies\n",
    "    ac = g.count_alleles().compute()\n",
    "    # only variant alleles matter, so only take those\n",
    "    flt_var = ac.is_variant()\n",
    "    print('variant filter passes:', flt_var.sum())\n",
    "    flt = (flt & flt_var)\n",
    "\n",
    "    if IGNORE_ONE_CALL_VARIANTS:\n",
    "        flt_one_call = ac[:,1:].sum(axis=1)>1\n",
    "        print('ignore-one-call variant filter passes:', flt_one_call.sum())\n",
    "        flt = (flt & flt_one_call)\n",
    "\n",
    "    ac = ac.compress(flt, axis=0)\n",
    "    vpos = pos.compress(flt, axis=0) # `[:]` to loads into memory\n",
    "\n",
    "    n_variants_var = ac.shape[0]\n",
    "    print(\"variants : {} of {} = {:.3f}%\".format(n_variants_var, n_variants_in,\n",
    "                                                     100*n_variants_var/n_variants_in))\n",
    "    seqdiv[chrom] = allel.sequence_diversity(vpos, ac, is_accessible=acc_mask)\n",
    "seqdiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T22:34:35.107930Z",
     "start_time": "2019-07-11T22:34:35.095793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('1', 5592763), ('2', 9206495), ('3', 8315366)])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VGL-Aaeg</th>\n",
       "      <td>0.010524</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>0.00879</td>\n",
       "      <td>0.009381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1         2        3   overall\n",
       "VGL-Aaeg  0.010524  0.009222  0.00879  0.009381"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(numloci)\n",
    "\n",
    "d = pd.DataFrame(seqdiv, index=[SETNAME])\n",
    "# compute weighted (by number of accessible loci) average\n",
    "d['overall'] = sum([d[k]*numloci[k] for k in numloci.keys()])/sum(numloci.values())\n",
    "# print(d.to_string())\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-11T22:34:36.569069Z",
     "start_time": "2019-07-11T22:34:35.109091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VGL-Aaeg median</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGL-Aaeg mean</th>\n",
       "      <td>10.285799</td>\n",
       "      <td>10.514316</td>\n",
       "      <td>10.665598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VGL-Aaeg std</th>\n",
       "      <td>7.096819</td>\n",
       "      <td>6.669656</td>\n",
       "      <td>7.110822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         1          2          3\n",
       "VGL-Aaeg median  10.000000  10.000000  10.000000\n",
       "VGL-Aaeg mean    10.285799  10.514316  10.665598\n",
       "VGL-Aaeg std      7.096819   6.669656   7.110822"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGL-Aaeg overall median converage (across acc loci): 10.0\n",
      "overall mean: 10.513447638922914\n"
     ]
    }
   ],
   "source": [
    "dpdf = pd.DataFrame(dpmedian, index=[SETNAME+' median'])\n",
    "dpdf.loc[SETNAME+' mean',:] = dpmean\n",
    "dpdf.loc[SETNAME+' std',:] = dpstd\n",
    "\n",
    "display(dpdf)\n",
    "print(SETNAME, 'overall median converage (across acc loci):', np.median(dpall))\n",
    "\n",
    "print('overall mean:', sum([dpmean[k]*numloci[k] for k in numloci.keys()])/sum(numloci.values()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
