{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chopchop targets across coding genes and population variation\n",
    "Simplifying down from 'scratch' version\n",
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T19:04:15.143416Z",
     "start_time": "2019-07-09T19:04:14.216887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.7 | packaged by conda-forge | (default, Feb 28 2019, 09:07:38) \n",
      "[GCC 7.3.0]\n",
      "numpy 1.16.2\n",
      "pandas 0.24.1\n",
      "scikit-allel 1.2.0\n",
      "zarr 2.2.0\n",
      "statsmodels 0.9.0\n"
     ]
    }
   ],
   "source": [
    "import sys; print(sys.version)\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "import io\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "\n",
    "import numpy as np; print('numpy', np.__version__)\n",
    "import pandas as pd; print('pandas',pd.__version__)\n",
    "import allel; print('scikit-allel', allel.__version__)\n",
    "import zarr; print('zarr', zarr.__version__)\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "import statsmodels; print('statsmodels', statsmodels.__version__)\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T19:04:15.150021Z",
     "start_time": "2019-07-09T19:04:15.144976Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "mpl.rcParams['figure.facecolor'] = '#BBBBBB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute sample list for Regional comparisons (@TCC WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T19:04:16.335089Z",
     "start_time": "2019-07-09T19:04:16.328853Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    d = pd.read_excel('vcfs/YL-Agam-GF2.xlsx')\n",
    "    d = d[(d['Country']=='Mali') & (d['Note']=='YL')]['Sample']\n",
    "\n",
    "    # samples which don't occur in Hanno's list\n",
    "    d2 = pd.read_csv('/data/vcfs/hanno_Agam_sample_list.txt', header=None)[0]\n",
    "    display(np.setdiff1d(d,d2))\n",
    "    # print(\"\\n\".join(d))\n",
    "\n",
    "    samp_list = np.intersect1d(d,d2)\n",
    "    display(samp_list)\n",
    "    display(samp_list.shape)\n",
    "\n",
    "    print(\"\\n\".join(samp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T19:04:16.793741Z",
     "start_time": "2019-07-09T19:04:16.788001Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    d = pd.read_excel('/data/vcfs/YL-Agam-GF2.xlsx')\n",
    "    d = d[(d['Country']=='Comoros') & (d['Note']=='YL')]['Sample']\n",
    "\n",
    "    # samples which don't occur in Hanno's list\n",
    "    d2 = pd.read_csv('/data/vcfs/hanno_Agam_sample_list.txt', header=None)[0]\n",
    "    display(np.setdiff1d(d,d2))\n",
    "    # print(\"\\n\".join(d))\n",
    "\n",
    "    samp_list = np.intersect1d(d,d2)\n",
    "    display(samp_list)\n",
    "    display(samp_list.shape)\n",
    "\n",
    "    print(\"\\n\".join(samp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings/Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T19:04:24.064108Z",
     "start_time": "2019-07-09T19:04:24.056787Z"
    }
   },
   "outputs": [],
   "source": [
    "SUBSAMPLE_N = None  # randomly select this many samples for testing sample size effects\n",
    "IGNORE_ONE_CALL_VARIANTS = False\n",
    "\n",
    "## Uncommnet block for the appropriate set of samples\n",
    "\n",
    "## An. gambiae\n",
    "SETNAME = 'VGL-gam'\n",
    "GENOME = \"AgamP4.11\"\n",
    "GENE_PREFIX = \"AGAP\"\n",
    "CHROMS = ['2R','2L','3R','3L','X']\n",
    "GTFFN = \"../datafiles/Anopheles-gambiae-PEST_BASEFEATURES_AgamP4.11.gtf\"\n",
    "ZVCF = 'vcfs/YL-Agam-GF2_pflit.vcf.gz.zarr'\n",
    "SAMPLE_LIST_FN = 'vcfs/hanno_Agam_sample_list.txt'\n",
    "\n",
    "# ## An. coluzzii\n",
    "# SETNAME = 'VGL-col'\n",
    "# GENOME = \"AgamP4.11\"\n",
    "# GENE_PREFIX = \"AGAP\"\n",
    "# CHROMS = ['2R','2L','3R','3L','X']#,'Y_unplaced','UNKN','Mt']\n",
    "# GTFFN = \"../datafiles/Anopheles-gambiae-PEST_BASEFEATURES_AgamP4.11.gtf\"\n",
    "# ZVCF = \"vcfs/100Acol_pflit.vcf.gz.zarr\"\n",
    "# SAMPLE_LIST_FN = None # use all samples in ZVCF\n",
    "\n",
    "# ## Ae. aegypti\n",
    "# SETNAME = 'VGL-Aaeg'\n",
    "# GENOME = \"Aaegypti_L5.1\"\n",
    "# GENE_PREFIX = \"AAEL\"\n",
    "# CHROMS = ['1','2','3']\n",
    "# GTFFN = \"../datafiles/Aedes-aegypti-LVP_AGWG_BASEFEATURES_AaegL5.1.gtf\"\n",
    "# ZVCF = \"vcfs/YL-Aaeg-03_pflit.vcf.gz.zarr\"\n",
    "# SAMPLE_LIST_FN = None # use all samples in ZVCF\n",
    "\n",
    "# ## Ag1000G An. gambiae\n",
    "# SETNAME = 'Ag1000g-gam'\n",
    "# GENOME = \"AgamP4.11\"\n",
    "# GENE_PREFIX = \"AGAP\"\n",
    "# CHROMS = ['2R','2L','3R','3L','X']\n",
    "# GTFFN = \"../datafiles/Anopheles-gambiae-PEST_BASEFEATURES_AgamP4.11.gtf\"\n",
    "# ZVCF = '/data/ag1000g_p2_ar1/ngs.sanger.ac.uk/production/ag1000g/phase2/AR1/variation/main/vcf/all/ag1000g.phase2.ar1.zarr'\n",
    "# SAMPLE_LIST_FN = ['S', '/data/ag1000g_p2_ar1/samples/samples.meta.txt'] # list implies ag1000g to be filtered on m_s\n",
    "\n",
    "## Ag1000G An. coluzzii\n",
    "# SETNAME = 'Ag1000g-col'\n",
    "# GENOME = \"AgamP4.11\"\n",
    "# GENE_PREFIX = \"AGAP\"\n",
    "# CHROMS = ['2R','2L','3R','3L','X']\n",
    "# GTFFN = \"../datafiles/Anopheles-gambiae-PEST_BASEFEATURES_AgamP4.11.gtf\"\n",
    "# ZVCF = '/data/ag1000g_p2_ar1/ngs.sanger.ac.uk/production/ag1000g/phase2/AR1/variation/main/vcf/all/ag1000g.phase2.ar1.zarr'\n",
    "# SAMPLE_LIST_FN = ['M', '/data/ag1000g_p2_ar1/samples/samples.meta.txt'] # list implies ag1000g to be filtered on m_s\n",
    "\n",
    "## *Regional* An. gambiae\n",
    "# GENOME = \"AgamP4.11\"\n",
    "# GENE_PREFIX = \"AGAP\"\n",
    "# CHROMS = ['2R','2L','3R','3L','X']\n",
    "# GTFFN = \"../datafiles/Anopheles-gambiae-PEST_BASEFEATURES_AgamP4.11.gtf\"\n",
    "# ZVCF = 'vcfs/YL-Agam-GF2_pflit.vcf.gz.zarr'\n",
    "# SUBSAMPLE_N = 40\n",
    "## Mali\n",
    "# SAMPLE_LIST_FN = 'vcfs/YL-Agam-GF2_Mali_samples_good.txt' # 40\n",
    "## or Comoros\n",
    "# SAMPLE_LIST_FN = 'vcfs/YL-Agam-GF2_Comoros_samples_good.txt' # 54\n",
    "## or ALL\n",
    "# SAMPLE_LIST_FN = 'vcfs/hanno_Agam_sample_list.txt'\n",
    "\n",
    "##########\n",
    "## Below shouldn't need changing\n",
    "\n",
    "TRANSFN = \"../datafiles/transcript_list_{}\".format(GENOME)\n",
    "CHOPCHOP_OUT_DIR = \"../all_transcripts_run/\".format(GENOME)\n",
    "\n",
    "if IGNORE_ONE_CALL_VARIANTS:\n",
    "    SETNAME = SETNAME+'_ignore-one-call'\n",
    "\n",
    "MIN_GC = 30 # minimum allowable GC percentage (inclusive)\n",
    "MAX_GC = 70 # maximum allowable GC percentage (inclusive)\n",
    "MAX_OFFTARGET_HITS = 0 # maximum allowable total offtarget hits\n",
    "\n",
    "AWK_EXEC = '/usr/bin/awk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T19:04:41.701381Z",
     "start_time": "2019-07-09T19:04:41.698523Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dict = OrderedDict()  # to collect results for final display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the callset and possibly set `CHROMS` to all\n",
    "note: callset isn't actually used til near the end where we're looking at variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T19:04:43.235590Z",
     "start_time": "2019-07-09T19:04:43.000696Z"
    }
   },
   "outputs": [],
   "source": [
    "callset = zarr.open_group(ZVCF, mode='r')\n",
    "if CHROMS is None: # use all chroms?\n",
    "    CHROMS = list(callset.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the (optional) subset of samples to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T19:04:44.542023Z",
     "start_time": "2019-07-09T19:04:43.900620Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples 111\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>callset_idx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>06BANA0008</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06BANA0010</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06BANA0012</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06BANA0013</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06BANA0016</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06BANA0035</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06DONE0022</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06DONE0044</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06DONE0045</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06DONE0046</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06DONE0104</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06DONE0132</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06FARA0003</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06FARA0004</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06FARA0007</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06FARA0008</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06FARA0009</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06FOUM0032</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06FOUM0033</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06FOUM0035</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06FOUM0036</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06FOUM0037</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06FOUN0009</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06FOUN0010</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06FOUN0026</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06FOUN0028</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06KELA0003</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06KELA0016</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06KELA0066</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06KELA0084</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011MUT045</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011MUT046</th>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011OSS001</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011OSS012</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011OSS013</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011OSS017</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011OSS018</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011OSS027</th>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011SAL001</th>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011SAL003</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011SAL005</th>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011SAL008</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011WAN033</th>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011WAN035</th>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011WAN041</th>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011WAN042</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011WAN043</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011WAN045</th>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012TNZK004</th>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012TNZK039</th>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012TNZK042</th>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012TNZK044</th>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012TNZK048</th>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012TNZK057</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015NCHE001</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015NCHE002</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015NCHE003</th>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015NCHE004</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015NCHE005</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015NCHE006</th>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>111 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             callset_idx\n",
       "sample                  \n",
       "06BANA0008             0\n",
       "06BANA0010             1\n",
       "06BANA0012             2\n",
       "06BANA0013             3\n",
       "06BANA0016             4\n",
       "06BANA0035             5\n",
       "06DONE0022             6\n",
       "06DONE0044             7\n",
       "06DONE0045             8\n",
       "06DONE0046             9\n",
       "06DONE0104            10\n",
       "06DONE0132            11\n",
       "06FARA0003            12\n",
       "06FARA0004            13\n",
       "06FARA0007            15\n",
       "06FARA0008            16\n",
       "06FARA0009            17\n",
       "06FOUM0032            18\n",
       "06FOUM0033            19\n",
       "06FOUM0035            20\n",
       "06FOUM0036            21\n",
       "06FOUM0037            22\n",
       "06FOUN0009            25\n",
       "06FOUN0010            26\n",
       "06FOUN0026            27\n",
       "06FOUN0028            28\n",
       "06KELA0003            29\n",
       "06KELA0016            30\n",
       "06KELA0066            31\n",
       "06KELA0084            33\n",
       "...                  ...\n",
       "2011MUT045            89\n",
       "2011MUT046            90\n",
       "2011OSS001            91\n",
       "2011OSS012            92\n",
       "2011OSS013            93\n",
       "2011OSS017            94\n",
       "2011OSS018            95\n",
       "2011OSS027            96\n",
       "2011SAL001            97\n",
       "2011SAL003            98\n",
       "2011SAL005            99\n",
       "2011SAL008           100\n",
       "2011WAN033           101\n",
       "2011WAN035           102\n",
       "2011WAN041           103\n",
       "2011WAN042           104\n",
       "2011WAN043           105\n",
       "2011WAN045           106\n",
       "2012TNZK004          107\n",
       "2012TNZK039          108\n",
       "2012TNZK042          109\n",
       "2012TNZK044          110\n",
       "2012TNZK048          111\n",
       "2012TNZK057          112\n",
       "2015NCHE001          113\n",
       "2015NCHE002          114\n",
       "2015NCHE003          115\n",
       "2015NCHE004          116\n",
       "2015NCHE005          117\n",
       "2015NCHE006          118\n",
       "\n",
       "[111 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if SAMPLE_LIST_FN is None: # use all samples\n",
    "    meta = pd.DataFrame(list(callset.values())[0]['samples'][:])\n",
    "    meta['callset_idx'] = range(meta.shape[0])\n",
    "else:\n",
    "    # load the sample list and make meta dataframe\n",
    "    if isinstance(SAMPLE_LIST_FN, str): # assume a simple list file\n",
    "        meta = pd.read_csv(SAMPLE_LIST_FN, comment='#', header=None, index_col=0)\n",
    "    else: # parse ag1000g samples.meta.txt with SAMPLE_LIST_FN really being [M|S,filename]\n",
    "        meta = pd.read_csv(SAMPLE_LIST_FN[1], delimiter='\\t', comment='#', index_col=0)\n",
    "        meta = meta[meta['m_s']==SAMPLE_LIST_FN[0]]\n",
    "    all_callset_samples = list(list(callset.values())[0]['samples'])\n",
    "    meta['callset_idx'] = [all_callset_samples.index(x) for x in meta.index]\n",
    "meta.index.name = 'sample'\n",
    "\n",
    "# Optionally subsample to check sample size effects\n",
    "if SUBSAMPLE_N:\n",
    "    meta = meta.sample(n=SUBSAMPLE_N)\n",
    "\n",
    "# ensure it is sorted by callset_idx (otherwise makes later steps terribly inefficient)\n",
    "meta = meta.sort_values('callset_idx')\n",
    "\n",
    "print(\"number of samples\",meta.shape[0])\n",
    "results_dict['number of samples'] = meta.shape[0]\n",
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the trascript list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T19:05:09.356168Z",
     "start_time": "2019-07-09T19:05:09.290196Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript_id</th>\n",
       "      <th>gene</th>\n",
       "      <th>splice_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGAP004677-RB</td>\n",
       "      <td>AGAP004677</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGAP004677-RA</td>\n",
       "      <td>AGAP004677</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGAP004678-RA</td>\n",
       "      <td>AGAP004678</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AGAP004679-RB</td>\n",
       "      <td>AGAP004679</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGAP004679-RA</td>\n",
       "      <td>AGAP004679</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AGAP004680-RA</td>\n",
       "      <td>AGAP004680</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGAP004681-RA</td>\n",
       "      <td>AGAP004681</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AGAP004682-RA</td>\n",
       "      <td>AGAP004682</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AGAP028431-RA</td>\n",
       "      <td>AGAP028431</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AGAP004683-RA</td>\n",
       "      <td>AGAP004683</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AGAP004684-RA</td>\n",
       "      <td>AGAP004684</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AGAP004685-RA</td>\n",
       "      <td>AGAP004685</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AGAP004685-RB</td>\n",
       "      <td>AGAP004685</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AGAP004686-RA</td>\n",
       "      <td>AGAP004686</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AGAP004687-RA</td>\n",
       "      <td>AGAP004687</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AGAP028432-RA</td>\n",
       "      <td>AGAP028432</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AGAP004688-RA</td>\n",
       "      <td>AGAP004688</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AGAP004689-RA</td>\n",
       "      <td>AGAP004689</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AGAP004689-RB</td>\n",
       "      <td>AGAP004689</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AGAP004689-RC</td>\n",
       "      <td>AGAP004689</td>\n",
       "      <td>RC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AGAP004690-RA</td>\n",
       "      <td>AGAP004690</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>AGAP029344-RA</td>\n",
       "      <td>AGAP029344</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>AGAP004691-RA</td>\n",
       "      <td>AGAP004691</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AGAP028433-RA</td>\n",
       "      <td>AGAP028433</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AGAP004692-RA</td>\n",
       "      <td>AGAP004692</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>AGAP004692-RB</td>\n",
       "      <td>AGAP004692</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AGAP004692-RC</td>\n",
       "      <td>AGAP004692</td>\n",
       "      <td>RC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>AGAP004692-RD</td>\n",
       "      <td>AGAP004692</td>\n",
       "      <td>RD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>AGAP004693-RA</td>\n",
       "      <td>AGAP004693</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AGAP004694-RA</td>\n",
       "      <td>AGAP004694</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15682</th>\n",
       "      <td>AGAP001083-RA</td>\n",
       "      <td>AGAP001083</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15683</th>\n",
       "      <td>AGAP001083-RD</td>\n",
       "      <td>AGAP001083</td>\n",
       "      <td>RD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15684</th>\n",
       "      <td>AGAP001083-RB</td>\n",
       "      <td>AGAP001083</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15685</th>\n",
       "      <td>AGAP001083-RC</td>\n",
       "      <td>AGAP001083</td>\n",
       "      <td>RC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15686</th>\n",
       "      <td>AGAP001084-RA</td>\n",
       "      <td>AGAP001084</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15687</th>\n",
       "      <td>AGAP001085-RA</td>\n",
       "      <td>AGAP001085</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15688</th>\n",
       "      <td>AGAP013547-RA</td>\n",
       "      <td>AGAP013547</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15689</th>\n",
       "      <td>AGAP001087-RA</td>\n",
       "      <td>AGAP001087</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15690</th>\n",
       "      <td>AGAP028971-RA</td>\n",
       "      <td>AGAP028971</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15691</th>\n",
       "      <td>AGAP028970-RA</td>\n",
       "      <td>AGAP028970</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15692</th>\n",
       "      <td>AGAP028968-RA</td>\n",
       "      <td>AGAP028968</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15693</th>\n",
       "      <td>AGAP028976-RA</td>\n",
       "      <td>AGAP028976</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15694</th>\n",
       "      <td>AGAP028979-RA</td>\n",
       "      <td>AGAP028979</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15695</th>\n",
       "      <td>AGAP001088-RA</td>\n",
       "      <td>AGAP001088</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15696</th>\n",
       "      <td>AGAP001089-RA</td>\n",
       "      <td>AGAP001089</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15697</th>\n",
       "      <td>AGAP013341-RA</td>\n",
       "      <td>AGAP013341</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15698</th>\n",
       "      <td>AGAP001090-RA</td>\n",
       "      <td>AGAP001090</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15699</th>\n",
       "      <td>AGAP013312-RA</td>\n",
       "      <td>AGAP013312</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15700</th>\n",
       "      <td>AGAP001091-RB</td>\n",
       "      <td>AGAP001091</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15701</th>\n",
       "      <td>AGAP001091-RA</td>\n",
       "      <td>AGAP001091</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15702</th>\n",
       "      <td>AGAP001092-RA</td>\n",
       "      <td>AGAP001092</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15703</th>\n",
       "      <td>AGAP001093-RA</td>\n",
       "      <td>AGAP001093</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15704</th>\n",
       "      <td>AGAP001094-RA</td>\n",
       "      <td>AGAP001094</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15705</th>\n",
       "      <td>AGAP028966-RA</td>\n",
       "      <td>AGAP028966</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15706</th>\n",
       "      <td>AGAP028977-RA</td>\n",
       "      <td>AGAP028977</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15707</th>\n",
       "      <td>AGAP028980-RA</td>\n",
       "      <td>AGAP028980</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15708</th>\n",
       "      <td>AGAP028967-RA</td>\n",
       "      <td>AGAP028967</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15709</th>\n",
       "      <td>AGAP028974-RA</td>\n",
       "      <td>AGAP028974</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15710</th>\n",
       "      <td>AGAP029221-RA</td>\n",
       "      <td>AGAP029221</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15711</th>\n",
       "      <td>AGAP029375-RA</td>\n",
       "      <td>AGAP029375</td>\n",
       "      <td>RA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15712 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       transcript_id        gene splice_id\n",
       "0      AGAP004677-RB  AGAP004677        RB\n",
       "1      AGAP004677-RA  AGAP004677        RA\n",
       "2      AGAP004678-RA  AGAP004678        RA\n",
       "3      AGAP004679-RB  AGAP004679        RB\n",
       "4      AGAP004679-RA  AGAP004679        RA\n",
       "5      AGAP004680-RA  AGAP004680        RA\n",
       "6      AGAP004681-RA  AGAP004681        RA\n",
       "7      AGAP004682-RA  AGAP004682        RA\n",
       "8      AGAP028431-RA  AGAP028431        RA\n",
       "9      AGAP004683-RA  AGAP004683        RA\n",
       "10     AGAP004684-RA  AGAP004684        RA\n",
       "11     AGAP004685-RA  AGAP004685        RA\n",
       "12     AGAP004685-RB  AGAP004685        RB\n",
       "13     AGAP004686-RA  AGAP004686        RA\n",
       "14     AGAP004687-RA  AGAP004687        RA\n",
       "15     AGAP028432-RA  AGAP028432        RA\n",
       "16     AGAP004688-RA  AGAP004688        RA\n",
       "17     AGAP004689-RA  AGAP004689        RA\n",
       "18     AGAP004689-RB  AGAP004689        RB\n",
       "19     AGAP004689-RC  AGAP004689        RC\n",
       "20     AGAP004690-RA  AGAP004690        RA\n",
       "21     AGAP029344-RA  AGAP029344        RA\n",
       "22     AGAP004691-RA  AGAP004691        RA\n",
       "23     AGAP028433-RA  AGAP028433        RA\n",
       "24     AGAP004692-RA  AGAP004692        RA\n",
       "25     AGAP004692-RB  AGAP004692        RB\n",
       "26     AGAP004692-RC  AGAP004692        RC\n",
       "27     AGAP004692-RD  AGAP004692        RD\n",
       "28     AGAP004693-RA  AGAP004693        RA\n",
       "29     AGAP004694-RA  AGAP004694        RA\n",
       "...              ...         ...       ...\n",
       "15682  AGAP001083-RA  AGAP001083        RA\n",
       "15683  AGAP001083-RD  AGAP001083        RD\n",
       "15684  AGAP001083-RB  AGAP001083        RB\n",
       "15685  AGAP001083-RC  AGAP001083        RC\n",
       "15686  AGAP001084-RA  AGAP001084        RA\n",
       "15687  AGAP001085-RA  AGAP001085        RA\n",
       "15688  AGAP013547-RA  AGAP013547        RA\n",
       "15689  AGAP001087-RA  AGAP001087        RA\n",
       "15690  AGAP028971-RA  AGAP028971        RA\n",
       "15691  AGAP028970-RA  AGAP028970        RA\n",
       "15692  AGAP028968-RA  AGAP028968        RA\n",
       "15693  AGAP028976-RA  AGAP028976        RA\n",
       "15694  AGAP028979-RA  AGAP028979        RA\n",
       "15695  AGAP001088-RA  AGAP001088        RA\n",
       "15696  AGAP001089-RA  AGAP001089        RA\n",
       "15697  AGAP013341-RA  AGAP013341        RA\n",
       "15698  AGAP001090-RA  AGAP001090        RA\n",
       "15699  AGAP013312-RA  AGAP013312        RA\n",
       "15700  AGAP001091-RB  AGAP001091        RB\n",
       "15701  AGAP001091-RA  AGAP001091        RA\n",
       "15702  AGAP001092-RA  AGAP001092        RA\n",
       "15703  AGAP001093-RA  AGAP001093        RA\n",
       "15704  AGAP001094-RA  AGAP001094        RA\n",
       "15705  AGAP028966-RA  AGAP028966        RA\n",
       "15706  AGAP028977-RA  AGAP028977        RA\n",
       "15707  AGAP028980-RA  AGAP028980        RA\n",
       "15708  AGAP028967-RA  AGAP028967        RA\n",
       "15709  AGAP028974-RA  AGAP028974        RA\n",
       "15710  AGAP029221-RA  AGAP029221        RA\n",
       "15711  AGAP029375-RA  AGAP029375        RA\n",
       "\n",
       "[15712 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tlist = pd.read_csv(TRANSFN, header=None, names=['transcript_id'])\n",
    "t = tlist['transcript_id'].str.rsplit('-', n=1, expand=True)\n",
    "t.columns = ['gene', 'splice_id']\n",
    "tlist = pd.concat((tlist,t), axis=1)\n",
    "tlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want \"transcribed parts (transcripts) of protein-coding genes\"\n",
    "What we're actually doing is including targets hitting a trascript which contains a CDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T19:05:10.935713Z",
     "start_time": "2019-07-09T19:05:10.161033Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of genes in gtf: 13822\n",
      "# trascripts with CDS: 14488\n",
      "# genes with a transcript with a CDS: 12562\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv(GTFFN, sep='\\t', comment='#', header=None,\n",
    "            names=['seqid',\n",
    "                   'source',\n",
    "                   'type',\n",
    "                   'start',\n",
    "                   'end',\n",
    "                   'score',\n",
    "                   'strand',\n",
    "                   'phase',\n",
    "                   'attributes'],\n",
    "                dtype={'seqid':str})\n",
    "\n",
    "# total number of genes\n",
    "t = d.loc[d['type']=='gene' ,:].copy(deep=True)\n",
    "t['gene_id'] = t['attributes'].apply(\n",
    "                    lambda x: dict([_.strip().split() for _ in\n",
    "                    x.split(';') if _])['gene_id'].strip('\"'))\n",
    "print(\"total number of genes in gtf:\", t['gene_id'].unique().shape[0])\n",
    "results_dict['total genes'] = t['gene_id'].unique().shape[0]\n",
    "\n",
    "# list of CDS\n",
    "d = d.loc[d['type']=='CDS' ,:]\n",
    "d['gene_id'] = d['attributes'].apply(\n",
    "                    lambda x: dict([_.strip().split() for _ in\n",
    "                    x.split(';') if _])['gene_id'].strip('\"'))\n",
    "d['transcript_id'] = d['attributes'].apply(\n",
    "                    lambda x: dict([_.strip().split() for _ in\n",
    "                    x.split(';') if _])['transcript_id'].strip('\"'))\n",
    "# filter to only CRHOMS\n",
    "d = d.loc[d['seqid'].isin(CHROMS) ,:]\n",
    "cdslist = d\n",
    "\n",
    "assert len(set(cdslist['transcript_id'])-set(tlist['transcript_id'])) == 0 # transcripts should be superset of CDS\n",
    "tcdslist = set(tlist['transcript_id']) & set(cdslist['transcript_id'])\n",
    "tcdsdf = tlist[tlist['transcript_id'].isin(tcdslist)]\n",
    "print('# trascripts with CDS:', len(tcdslist))\n",
    "results_dict['coding transcripts'] = len(tcdslist)\n",
    "\n",
    "num_coding_genes = tcdsdf['gene'].unique().shape[0]\n",
    "print('# genes with a transcript with a CDS:', num_coding_genes)\n",
    "results_dict['coding genes'] = tcdsdf['gene'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T20:20:07.515858Z",
     "start_time": "2019-07-09T20:20:07.483490Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the chopchop targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T21:09:02.647535Z",
     "start_time": "2019-07-08T21:08:50.600550Z"
    }
   },
   "outputs": [],
   "source": [
    "# use awk to append the transcript_ids and merge all the chopchop outputs\n",
    "# stream than into pandas.read_csv\n",
    "cmd = (AWK_EXEC+\" -F \"+r\"'\\t' \"\n",
    "\"'BEGIN{OFS=FS}{if(FNR==1){if(NR==FNR){print $0, \"+'\"transcript_id\"'+\"}}else{print $0, FILENAME}}' \"+\n",
    "\"{}/{}*\".format(GENOME, GENE_PREFIX))\n",
    "\n",
    "print(cmd)\n",
    "with subprocess.Popen(cmd, cwd=CHOPCHOP_OUT_DIR, shell=True, stdout=subprocess.PIPE) as p:\n",
    "    d_orig = pd.read_csv(p.stdout, sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T21:09:05.896608Z",
     "start_time": "2019-07-08T21:09:02.648861Z"
    }
   },
   "outputs": [],
   "source": [
    "# make a copy of the full chopchop target list so just in case\n",
    "d = d_orig.copy(deep=True)\n",
    "d.reset_index(inplace=True)\n",
    "# remove the path from the transcript_id\n",
    "d['transcrpit_id_old'] = d['transcript_id']\n",
    "d['transcript_id'] = d['transcript_id'].apply(os.path.basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter chopchop targets `d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T21:09:11.190844Z",
     "start_time": "2019-07-08T21:09:05.897983Z"
    }
   },
   "outputs": [],
   "source": [
    "# restrict to transcripts containing a CDS\n",
    "d = d[d['transcript_id'].isin(tcdsdf['transcript_id'])]\n",
    "print(d.shape[0], \"initial target sites in coding transcripts\")\n",
    "results_dict['initial target sites in coding transcripts'] = d.shape[0]\n",
    "\n",
    "nuts = d['Genomic location'].unique().shape[0] # divisor for filter percents\n",
    "results_dict['unique location target sites'] = nuts\n",
    "\n",
    "print(nuts, 'unique genomic locations')\n",
    "print(d['Target sequence'].unique().shape[0], 'unique target sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-16T19:54:45.006669Z",
     "start_time": "2019-05-16T19:54:45.003797Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T21:09:13.576270Z",
     "start_time": "2019-07-08T21:09:11.192250Z"
    }
   },
   "outputs": [],
   "source": [
    "# set the >=555 sort of entries in the MM columns to 999\n",
    "d[\"sumMM\"] = d.loc[:,(\"MM0\",\"MM1\",\"MM2\",\"MM3\")].\\\n",
    "    apply(pd.to_numeric, errors='coerce').fillna(999).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T21:09:15.256591Z",
     "start_time": "2019-07-08T21:09:13.577452Z"
    }
   },
   "outputs": [],
   "source": [
    "# GC filter\n",
    "gc_flt = ((d[\"GC content (%)\"] >= MIN_GC) & (d[\"GC content (%)\"] <= MAX_GC))\n",
    "cnt = d.loc[gc_flt,'Genomic location'].unique().shape[0]\n",
    "print(\"unique pass GC filter {} ({}%)\".format(cnt, 100*cnt/nuts))\n",
    "results_dict['unique targets pass GC filter'] = cnt\n",
    "results_dict['unique targets pass GC filter %'] = 100*cnt/nuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T21:09:15.529015Z",
     "start_time": "2019-07-08T21:09:15.257950Z"
    }
   },
   "outputs": [],
   "source": [
    "# off-target filter\n",
    "offtarget_flt = (d[\"sumMM\"] <= MAX_OFFTARGET_HITS)\n",
    "cnt = d.loc[offtarget_flt,'Genomic location'].unique().shape[0]\n",
    "print(\"unique pass off-target {} ({}%)\".format(cnt, 100*cnt/nuts))\n",
    "results_dict['unique targets pass off-target filter'] = cnt\n",
    "results_dict['unique targets pass off-target filter %'] = 100*cnt/nuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T21:09:15.799162Z",
     "start_time": "2019-07-08T21:09:15.530470Z"
    }
   },
   "outputs": [],
   "source": [
    "cnt = d.loc[(gc_flt & offtarget_flt),'Genomic location'].unique().shape[0]\n",
    "print(\"unique pass both {} ({}%)\".format(cnt, 100*cnt/nuts))\n",
    "results_dict['unique targets pass filters'] = cnt\n",
    "results_dict['unique targets pass filters %'] = 100*cnt/nuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T21:09:18.509232Z",
     "start_time": "2019-07-08T21:09:15.800239Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = d['transcript_id'].unique().shape[0]\n",
    "\n",
    "# actually apply filters\n",
    "d = d.loc[(gc_flt & offtarget_flt),:]\n",
    "\n",
    "# add a gene column\n",
    "d['gene'] = d['transcript_id'].str.rsplit('-',1).str.get(0)\n",
    "\n",
    "print(\"{} passing targets (including duplicate sites)\".format(d.shape[0]))\n",
    "print(\"hitting {} of {} unique transcript_ids left after flitering {}\".format(\n",
    "        d['transcript_id'].unique().shape[0],\n",
    "        tmp,\n",
    "        d['transcript_id'].unique().shape[0]/tmp))\n",
    "chopchop_targets = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T21:09:18.514796Z",
     "start_time": "2019-07-08T21:09:18.511187Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T21:09:18.753293Z",
     "start_time": "2019-07-08T21:09:18.516292Z"
    }
   },
   "outputs": [],
   "source": [
    "chopchop_targets['Genomic location'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info on unique target+gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T21:10:58.642595Z",
     "start_time": "2019-07-08T21:10:55.874042Z"
    }
   },
   "outputs": [],
   "source": [
    "# Info on unique target+gene\n",
    "t = chopchop_targets.set_index('Genomic location').loc[:,('Target sequence','gene')]\n",
    "\n",
    "single_target_different_genes = t[t.index.duplicated() & ~t.duplicated()]\n",
    "print(single_target_different_genes.shape[0], \"targets hitting more than one gene\")\n",
    "print(single_target_different_genes['gene'].unique().shape[0], \"genes affected\")\n",
    "\n",
    "# filter to targets which are unique or hit different genes\n",
    "t = t[~t.duplicated(keep='first')]\n",
    "print(t.shape[0], 'unique target+gene combinations')\n",
    "\n",
    "# number of genes with 0 targets\n",
    "total_num_genes = tlist['gene'].unique().shape[0]\n",
    "num_0_target_genes = total_num_genes - t['gene'].unique().shape[0]\n",
    "print(num_0_target_genes, \"genes of\", total_num_genes, \"with no targets\")\n",
    "\n",
    "# sanity check\n",
    "assert t.shape[0]-single_target_different_genes.shape[0] == chopchop_targets['Genomic location'].unique().shape[0]\n",
    "\n",
    "# results_dict['coding genes with potential target'] = t['gene'].unique().shape[0]\n",
    "# results_dict['coding genes with potential target %'] = (100*\n",
    "#     results_dict['coding genes with potential target']/results_dict['coding genes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T21:10:58.659844Z",
     "start_time": "2019-07-08T21:10:58.644085Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(chopchop_targets.head())\n",
    "display(chopchop_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @TCC Exploring efficiency scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T21:28:16.575012Z",
     "start_time": "2019-07-08T21:28:16.540332Z"
    }
   },
   "outputs": [],
   "source": [
    "x = chopchop_targets\n",
    "y = x['Efficiency'].value_counts().sort_index()\n",
    "\n",
    "fig,ax = mpl.pyplot.subplots(1)\n",
    "ax.plot(y.index, y/y.sum())\n",
    "ax.set_xlabel('Xu et al. 2015 efficiency')\n",
    "ax.set_ylabel('proportion of targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T21:30:13.580146Z",
     "start_time": "2019-07-08T21:30:13.524487Z"
    }
   },
   "outputs": [],
   "source": [
    "y = x['Efficiency']\n",
    "print(y[y>.5].count())\n",
    "print(y.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## search vcf for target sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:42:57.468474Z",
     "start_time": "2019-06-12T19:42:57.456453Z"
    }
   },
   "outputs": [],
   "source": [
    "# all target sequences are the same length\n",
    "TARGET_LEN = len(chopchop_targets.iloc[0]['Target sequence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get variant positiosn from the callset (zvcf)\n",
    "Note: callset is opened way up top in case we need to get `CHROMS` from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:47:54.221525Z",
     "start_time": "2019-06-12T19:42:57.470632Z"
    }
   },
   "outputs": [],
   "source": [
    "refAF_dict = OrderedDict()\n",
    "vpos_dict = OrderedDict()\n",
    "results_dict['vcf variants'] = 0\n",
    "results_dict['variants'] = 0\n",
    "\n",
    "for chrom in CHROMS:\n",
    "    print(\"chrom:\", chrom)\n",
    "    \n",
    "    ## Get the positions of variants on this chrom (possible subsetting samples)\n",
    "    pos = allel.SortedIndex(callset[chrom]['variants/POS'])\n",
    "    g = allel.GenotypeDaskArray(callset[chrom]['calldata/GT']).subset(None, meta['callset_idx'].values)\n",
    "    n_variants_in = g.shape[0]\n",
    "    \n",
    "    # ensure number of samples is same\n",
    "    assert meta.shape[0] == g.shape[1]\n",
    "    \n",
    "    # get major allele frequencies\n",
    "    ac = g.count_alleles().compute()\n",
    "    # only variant alleles matter, so only take those\n",
    "    flt_var = ac.is_variant()\n",
    "    print('variant filter passes:', flt_var.sum())\n",
    "    \n",
    "    if IGNORE_ONE_CALL_VARIANTS:\n",
    "        flt_one_call = ac[:,1:].sum(axis=1)>1\n",
    "        print('ignore-one-call variant filter passes:', flt_one_call.sum())\n",
    "        flt_var = (flt_var & flt_one_call)\n",
    "    \n",
    "    ac = ac.compress(flt_var, axis=0)\n",
    "    n_variants_var = ac.shape[0]\n",
    "\n",
    "    refAF_dict[chrom] = ac.to_frequencies(fill=1)[:,0] # ref should be allele index 0\n",
    "    vpos_dict[chrom] = pos.compress(flt_var, axis=0)[:] # `[:]` to loads into memory\n",
    "    \n",
    "    print(\"variants : {} of {} = {:.3f}%\".format(n_variants_var, n_variants_in,\n",
    "                                                 100*n_variants_var/n_variants_in))\n",
    "    results_dict['vcf variants'] += n_variants_in\n",
    "    results_dict['variants'] += n_variants_var\n",
    "        \n",
    "print('total variants :', results_dict['variants'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T19:05:10.939552Z",
     "start_time": "2019-07-09T19:05:10.937412Z"
    }
   },
   "outputs": [],
   "source": [
    "# tcdsdf.to_msgpack(GENOME+\"_tcdsdf.msgpack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-15T16:37:37.653730Z",
     "start_time": "2019-04-15T16:37:37.647371Z"
    }
   },
   "source": [
    "### Compare targets vs variants\n",
    "#### grouping by **gene**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:48:00.157615Z",
     "start_time": "2019-06-12T19:47:54.223205Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sort the filtered list of chopchop targets by chrom,pos (from Genomic location)\n",
    "d_filt = chopchop_targets.copy(deep=True)\n",
    "\n",
    "# keep only unique location, gene combinations...\n",
    "d_filt = d_filt.loc[d_filt[['Genomic location', 'gene']].drop_duplicates(keep='first').index]\n",
    "\n",
    "# add chrom and pos columns\n",
    "d_filt[['chrom','pos']] = d_filt['Genomic location'].str.split(':', n=1, expand=True)\n",
    "d_filt['pos'] = d_filt['pos'].astype(int)\n",
    "d_filt.sort_values(['chrom', 'pos'], inplace=True)\n",
    "\n",
    "display(d_filt.head())\n",
    "print(\"location by gene unique combinations:\",d_filt.shape[0])\n",
    "print(\"unique target locations:\",chopchop_targets['Genomic location'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:48:20.439877Z",
     "start_time": "2019-06-12T19:48:00.158954Z"
    }
   },
   "outputs": [],
   "source": [
    "tout = d_filt.copy(deep=True)\n",
    "tout['vpos'] = np.nan # position of each variant\n",
    "tout['nv'] = np.nan # number of variants\n",
    "tout['refAF'] = np.nan # frequency of reference allele of each variant\n",
    "tout['p_ref'] = np.nan # probability of ref sequence for whole target\n",
    "\n",
    "for chrom in CHROMS:\n",
    "    print(\"chrom:\", chrom)\n",
    "    vpos = vpos_dict[chrom]\n",
    "    \n",
    "    # target positions (target list is filtered above)\n",
    "    tpos = d_filt[d_filt['chrom']==chrom]['pos'].copy(deep=True)\n",
    "    print(\"unique (location,gene) targets:\", tpos.shape)\n",
    "\n",
    "    # find target positions in the list of variant positions\n",
    "    p1 = np.searchsorted(vpos, tpos.values, side='left')\n",
    "    p2 = np.searchsorted(vpos, tpos.values+TARGET_LEN, side='left')\n",
    "    \n",
    "    # list of actual variant positions in each target\n",
    "    tout.loc[tpos.index,'vpos'] = [vpos[_p1:_p2].values for _p1,_p2 in zip(p1,p2)]\n",
    "    # count of variants in each target\n",
    "    tout.loc[tpos.index,'nv'] = (p2-p1)\n",
    "    # refAF of each variant in each target\n",
    "    tout.loc[tpos.index,'refAF'] = [refAF_dict[chrom][_p1:_p2] for _p1,_p2 in zip(p1,p2)]\n",
    "    # the probability a target locus will be entirely reference (perfect match)\n",
    "    # assumes each variant hitting that target is independent\n",
    "    tout.loc[tpos.index,'p_ref'] = tout.loc[tpos.index,'refAF'].apply(lambda x: np.prod(x, initial=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T00:12:07.914662Z",
     "start_time": "2019-06-11T00:12:07.902606Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:49:10.096974Z",
     "start_time": "2019-06-12T19:48:20.441206Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Save tout to a file so we can use it to generate a nice figure\n",
    "tout.to_msgpack(SETNAME+\"_tout.msgpack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @TCC EVERYTHING BELOW SHOULD REALLY BE DONE BY 'RESULTS' SCRIPT\n",
    "Need to have saved\n",
    "* tout\n",
    "* number of coding genes (currently saved in results_dict below)\n",
    "* total number of unique targets (currently saved in results_dict below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relationship between variant freq and num genes with a good target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:49:10.100157Z",
     "start_time": "2019-06-12T19:49:10.098358Z"
    }
   },
   "outputs": [],
   "source": [
    "# tout = pd.read_msgpack(SETNAME+'_tout.msgpack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:49:12.934425Z",
     "start_time": "2019-06-12T19:49:10.102333Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key = 'Genomic location'\n",
    "t = tout[[key,'chrom','pos','nv','p_ref']].copy(deep=True)\n",
    "t.set_index(key, drop=True, inplace=True)\n",
    "t.drop_duplicates(inplace=True)\n",
    "t.reset_index(inplace=True)\n",
    "\n",
    "tx = np.sort(t['p_ref'])\n",
    "tnfixed = (tx>=1).sum()\n",
    "print('target nfixed', tnfixed)\n",
    "tx = tx[tx<1]\n",
    "ty = ((tnfixed+len(tx))-np.arange(len(tx)))/(len(tx)+tnfixed)\n",
    "\n",
    "\n",
    "t = tout[['gene','chrom','pos','nv','p_ref']].copy(deep=True)\n",
    "t.set_index('gene', drop=True, inplace=True)\n",
    "print(t.shape)\n",
    "t.drop_duplicates(inplace=True)\n",
    "t.reset_index(inplace=True)\n",
    "print(t.shape)\n",
    "\n",
    "gb = t[['gene','p_ref']].groupby('gene').apply(lambda x: [_ for _ in x['p_ref']])\n",
    "\n",
    "good_by_freq = gb.apply(max)\n",
    "num_coding_genes = tcdsdf['gene'].unique().shape[0]\n",
    "\n",
    "x = np.sort(good_by_freq) \n",
    "nfixed = (x>=1).sum()\n",
    "print('nfixed',nfixed)\n",
    "x = x[x<1]\n",
    "y = ((nfixed+len(x))-np.arange(len(x)))/num_coding_genes # <= x\n",
    "\n",
    "fig,ax = mpl.pyplot.subplots(1,1, figsize=(4,3))\n",
    "\n",
    "# ax.step(x,y, where='pre', c='C0', label='genes')\n",
    "# ax.step(tx,ty, where='pre', c='C1', label='targets')\n",
    "\n",
    "ax.plot(x,y, ls='none', marker='.', ms=3, c='C0', label='genes')\n",
    "ax.plot(tx,ty, ls='none', marker='.', ms=3, c='C1', label='targets')\n",
    "\n",
    "# ax.axhline(1, ls=':', lw=1, c='k')\n",
    "# ax.set_yscale('log')\n",
    "# ax.set_xscale('log')\n",
    "ax.set_xlim((.95,1))\n",
    "ax.set_ylim((0,1))\n",
    "\n",
    "ax.set_xlabel('required non-variant frequency')\n",
    "ax.set_ylabel('proportion')\n",
    "ax.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:49:12.946067Z",
     "start_time": "2019-06-12T19:49:12.935759Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp = pd.Series([2,2,3,4,5,6,6,6,6,7])\n",
    "pd.Series(tx).quantile(.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:49:12.953201Z",
     "start_time": "2019-06-12T19:49:12.947366Z"
    }
   },
   "outputs": [],
   "source": [
    "tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:49:14.062147Z",
     "start_time": "2019-06-12T19:49:12.954507Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = tout[['gene','transcript_id','chrom','pos','nv','p_ref','Genomic location']]\n",
    "\n",
    "# by target\n",
    "num_potential_targets = t.shape[0]\n",
    "print('num potential targets:', num_potential_targets)\n",
    "# results_dict['potential targets'] = t.shape[0]\n",
    "\n",
    "good_targets = t[t['nv']==0]\n",
    "print('num good targets:', good_targets.shape[0])\n",
    "print(\"% good targets: {:d}/{:d} = {:0.3f}%\".format(\n",
    "    good_targets.shape[0], num_potential_targets, 100*good_targets.shape[0]/num_potential_targets))\n",
    "\n",
    "# by unique target\n",
    "num_potential_unique_targets = t['Genomic location'].unique().shape[0]\n",
    "print('num potential unique targets:', num_potential_unique_targets)\n",
    "\n",
    "num_good_unique_targets = t[t['nv']==0]['Genomic location'].unique().shape[0]\n",
    "print('num good unique targets:', num_good_unique_targets)\n",
    "print(\"% good uniuqe targets: {:d}/{:d} = {:0.3f}%\".format(\n",
    "    num_good_unique_targets, num_potential_unique_targets,\n",
    "    100*num_good_unique_targets/num_potential_unique_targets))\n",
    "\n",
    "print(\"% good uniuqe targets of unique target sites: {:d}/{:d} = {:0.3f}%\".format(\n",
    "    num_good_unique_targets, chopchop_targets['Genomic location'].unique().shape[0],\n",
    "    100*num_good_unique_targets/chopchop_targets['Genomic location'].unique().shape[0]))\n",
    "\n",
    "results_dict['potential unique targets'] = num_potential_unique_targets\n",
    "results_dict['good unique targets'] = num_good_unique_targets\n",
    "results_dict['good unique targets % of total unique'] = (100*\n",
    "    results_dict['good unique targets']/results_dict['unique location target sites'])\n",
    "results_dict['good unique targets % of potential'] = (100*\n",
    "    results_dict['good unique targets']/results_dict['potential unique targets'])\n",
    "\n",
    "# by transcript\n",
    "### @TCC NOT CORRECT SINCE t (from d_filt) eliminates duplicates based on genomic location and gene (not transcript_id)\n",
    "# num_total_utcds = tcdsdf['transcript_id'].unique().shape[0]\n",
    "# num_potential_utcds = t['transcript_id'].unique().shape[0]\n",
    "# num_good_utcds = good_targets['transcript_id'].unique().shape[0]\n",
    "# print(\"num coding transcripts\", num_total_utcds)\n",
    "# print(\"% transcripts w/ potential uniuqe targets: {:d}/{:d} = {:0.2f}%\".format(\n",
    "#     num_potential_utcds, num_total_utcds,\n",
    "#     100*num_potential_utcds/num_total_utcds))\n",
    "# print(\"% transcripts w/ good uniuqe targets: {:d}/{:d} = {:0.2f}%\".format(\n",
    "#     num_good_utcds, num_total_utcds,\n",
    "#     100*num_good_utcds/num_total_utcds))\n",
    "\n",
    "# by gene\n",
    "num_coding_genes = tcdsdf['gene'].unique().shape[0]\n",
    "num_potential_genes = t['gene'].unique().shape[0]\n",
    "num_good_genes = good_targets['gene'].unique().shape[0]\n",
    "print(\"num coding genes\", num_coding_genes)\n",
    "print(\"% genes w/ potential uniuqe targets: {:d}/{:d} = {:0.3f}%\".format(\n",
    "    num_potential_genes, num_coding_genes,\n",
    "    100*num_potential_genes/num_coding_genes))\n",
    "print(\"% genes w/ good uniuqe targets: {:d}/{:d} = {:0.3f}%\".format(\n",
    "    num_good_genes, num_coding_genes,\n",
    "    100*num_good_genes/num_coding_genes))\n",
    "\n",
    "results_dict['coding genes w/ potential targets'] = num_potential_genes\n",
    "results_dict['coding genes w/ potential targets %'] = (100*\n",
    "    num_potential_genes/num_coding_genes)\n",
    "results_dict['coding genes w/ good targets'] = num_good_genes\n",
    "results_dict['coding genes w/ good targets %'] = (100*\n",
    "    num_good_genes/num_coding_genes)\n",
    "\n",
    "# display(good_targets['gene'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:49:14.067238Z",
     "start_time": "2019-06-12T19:49:14.063392Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rerunning with grouping by **transcript** to get good targets per transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:49:20.733658Z",
     "start_time": "2019-06-12T19:49:14.068357Z"
    }
   },
   "outputs": [],
   "source": [
    "# sort the filtered list of chopchop targets by chrom,pos (from Genomic location)\n",
    "d_filt = chopchop_targets.copy(deep=True)\n",
    "# keep only unique location, gene combinations...\n",
    "d_filt = d_filt.loc[d_filt[['Genomic location', 'transcript_id']].drop_duplicates(keep='first').index]\n",
    "# add chrom and pos columns\n",
    "d_filt[['chrom','pos']] = d_filt['Genomic location'].str.split(':', n=1, expand=True)\n",
    "d_filt['pos'] = d_filt['pos'].astype(int)\n",
    "d_filt.sort_values(['chrom', 'pos'], inplace=True)\n",
    "\n",
    "print(\"location by gene unique combinations:\",d_filt.shape[0])\n",
    "print(\"unique target locations:\",chopchop_targets['Genomic location'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:50:14.188937Z",
     "start_time": "2019-06-12T19:49:20.734973Z"
    }
   },
   "outputs": [],
   "source": [
    "tout = d_filt.copy(deep=True)\n",
    "tout['vpos'] = np.nan # position of each variant\n",
    "tout['nv'] = np.nan # number of variants\n",
    "tout['refAF'] = np.nan # frequency of reference allele of each variant\n",
    "tout['p_ref'] = np.nan # probability of ref sequence for whole target\n",
    "\n",
    "for chrom in CHROMS:\n",
    "    print(\"chrom:\", chrom)\n",
    "    vpos = vpos_dict[chrom]\n",
    "    \n",
    "    # target positions (target list is filtered above)\n",
    "    tpos = d_filt[d_filt['chrom']==chrom]['pos'].copy(deep=True)\n",
    "    print(\"unique (location,transcript) targets:\", tpos.shape)\n",
    "\n",
    "    # find target positions in the list of variant positions\n",
    "    p1 = np.searchsorted(vpos, tpos.values, side='left')\n",
    "    p2 = np.searchsorted(vpos, tpos.values+TARGET_LEN, side='left')\n",
    "    \n",
    "    # list of actual variant positions in each target\n",
    "    tout.loc[tpos.index,'vpos'] = [vpos[_p1:_p2] for _p1,_p2 in zip(p1,p2)]\n",
    "    # count of variants in each target\n",
    "    tout.loc[tpos.index,'nv'] = (p2-p1)\n",
    "    # refAF of each variant in each target\n",
    "    tout.loc[tpos.index,'refAF'] = [refAF_dict[chrom][_p1:_p2] for _p1,_p2 in zip(p1,p2)]\n",
    "    # the probability a target locus will be entirely reference (perfect match)\n",
    "    # assumes each variant hitting that target is independent\n",
    "    tout.loc[tpos.index,'p_ref'] = tout.loc[tpos.index,'refAF'].apply(lambda x: np.prod(x, initial=1))\n",
    "\n",
    "# summary statistics\n",
    "display(tout['nv'].value_counts())\n",
    "display(tout['nv'].describe())\n",
    "print('targets containting variant loci {:0.2f}%'.format(100*(tout['nv']==0).sum()/tout['nv'].count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:50:15.637723Z",
     "start_time": "2019-06-12T19:50:14.190787Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = tout[['gene','transcript_id','chrom','pos','nv','Genomic location']]\n",
    "\n",
    "# by target (should be same as per-gene calculations)\n",
    "num_potential_targets = t.shape[0]\n",
    "print('num potential targets:', num_potential_targets)\n",
    "\n",
    "good_targets = t[t['nv']==0]\n",
    "print('num good targets:', good_targets.shape[0])\n",
    "print(\"% good targets: {:d}/{:d} = {:0.3f}%\".format(\n",
    "    good_targets.shape[0], num_potential_targets, 100*good_targets.shape[0]/num_potential_targets))\n",
    "\n",
    "# by unique target (should be same as per-gene calculations)\n",
    "num_potential_unique_targets = t['Genomic location'].unique().shape[0]\n",
    "print('num potential unique targets:', num_potential_unique_targets)\n",
    "\n",
    "num_good_unique_targets = t[t['nv']==0]['Genomic location'].unique().shape[0]\n",
    "print('num good unique targets:', num_good_unique_targets)\n",
    "print(\"% good uniuqe targets: {:d}/{:d} = {:0.3f}%\".format(\n",
    "    num_good_unique_targets, num_potential_unique_targets,\n",
    "    100*num_good_unique_targets/num_potential_unique_targets))\n",
    "\n",
    "print(\"% good uniuqe targets of unique target sites: {:d}/{:d} = {:0.3f}%\".format(\n",
    "    num_good_unique_targets, chopchop_targets['Genomic location'].unique().shape[0],\n",
    "    100*num_good_unique_targets/chopchop_targets['Genomic location'].unique().shape[0]))\n",
    "\n",
    "# by transcript\n",
    "num_total_utcds = tcdsdf['transcript_id'].unique().shape[0]\n",
    "num_potential_utcds = t['transcript_id'].unique().shape[0]\n",
    "num_good_utcds = good_targets['transcript_id'].unique().shape[0]\n",
    "print(\"num coding transcripts\", num_total_utcds)\n",
    "print(\"% transcripts w/ potential uniuqe targets: {:d}/{:d} = {:0.2f}%\".format(\n",
    "    num_potential_utcds, num_total_utcds,\n",
    "    100*num_potential_utcds/num_total_utcds))\n",
    "print(\"% transcripts w/ good uniuqe targets: {:d}/{:d} = {:0.2f}%\".format(\n",
    "    num_good_utcds, num_total_utcds,\n",
    "    100*num_good_utcds/num_total_utcds))\n",
    "\n",
    "results_dict['coding transcripts w/ potential targets'] = num_potential_utcds\n",
    "results_dict['coding transcripts w/ potential targets %'] = (100*\n",
    "    num_potential_utcds/num_total_utcds)\n",
    "results_dict['coding transcripts w/ good targets'] = num_good_utcds\n",
    "results_dict['coding transcripts w/ good targets %'] = (100*\n",
    "    num_good_utcds/num_total_utcds)\n",
    "\n",
    "# by gene @TCC NOT NECISSARIALLY CORRECT SINCE REMOVED DUPLICATES BASED ON TRANSCRIPT AND LOCATION (NOT GENE)\n",
    "num_coding_genes = tcdsdf['gene'].unique().shape[0]\n",
    "num_potential_genes = t['gene'].unique().shape[0]\n",
    "num_good_genes = good_targets['gene'].unique().shape[0]\n",
    "print(\"num coding genes\", num_coding_genes)\n",
    "print(\"% genes w/ potential uniuqe targets: {:d}/{:d} = {:0.3f}%\".format(\n",
    "    num_potential_genes, num_coding_genes,\n",
    "    100*num_potential_genes/num_coding_genes))\n",
    "print(\"% genes w/ good uniuqe targets: {:d}/{:d} = {:0.3f}%\".format(\n",
    "    num_good_genes, num_coding_genes,\n",
    "    100*num_good_genes/num_coding_genes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:50:15.642719Z",
     "start_time": "2019-06-12T19:50:15.638937Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:50:15.657453Z",
     "start_time": "2019-06-12T19:50:15.643889Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(SETNAME+'_results.json','w') as fh:\n",
    "    json.dump(list(results_dict.items()), fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T19:50:15.669832Z",
     "start_time": "2019-06-12T19:50:15.659726Z"
    }
   },
   "outputs": [],
   "source": [
    "# with open(SETNAME+'_results.json','r') as fh:\n",
    "#     foo = OrderedDict(json.load(fh))\n",
    "# foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
